{"dependencies":[{"name":"/Users/senecamac1/henry/playing-with-tensorflow/fitting-a-curve/package.json","includedInParent":true,"mtime":1522495589000},{"name":"babel-runtime/regenerator"},{"name":"babel-runtime/helpers/asyncToGenerator"},{"name":"@tensorflow/tfjs","loc":{"line":18,"column":20}},{"name":"./data","loc":{"line":19,"column":29}},{"name":"./ui","loc":{"line":20,"column":69}}],"generated":{"js":"\"use strict\";\n\nvar _regenerator = require(\"babel-runtime/regenerator\");\n\nvar _regenerator2 = _interopRequireDefault(_regenerator);\n\nvar _asyncToGenerator2 = require(\"babel-runtime/helpers/asyncToGenerator\");\n\nvar _asyncToGenerator3 = _interopRequireDefault(_asyncToGenerator2);\n\nvar learnCoefficients = function () {\n  var _ref = (0, _asyncToGenerator3.default)( /*#__PURE__*/_regenerator2.default.mark(function _callee() {\n    var trueCoefficients, trainingData, iter, predictionsDuring, predictionsAfter;\n    return _regenerator2.default.wrap(function _callee$(_context) {\n      while (1) {\n        switch (_context.prev = _context.next) {\n          case 0:\n            //   const trueCoefficients = { a: -0.8, b: -0.2, c: 0.9, d: 0.5 };\n            trueCoefficients = {\n              a: randomNumber(),\n              b: randomNumber(),\n              c: randomNumber(),\n              d: randomNumber()\n            };\n            trainingData = (0, _data.generateData)(100, trueCoefficients);\n\n            //   // Train the model!\n            //   await train(trainingData.xs, trainingData.ys, numIterations);\n\n            iter = 0;\n\n          case 3:\n            if (!(iter < numIterations)) {\n              _context.next = 15;\n              break;\n            }\n\n            if (!(iter % 10 === 0)) {\n              _context.next = 9;\n              break;\n            }\n\n            (0, _ui.renderCoefficients)(\"#trained .coeff\", {\n              a: a.dataSync()[0],\n              b: b.dataSync()[0],\n              c: c.dataSync()[0],\n              d: d.dataSync()[0]\n            }, iter);\n\n            predictionsDuring = predict(trainingData.xs);\n            _context.next = 9;\n            return (0, _ui.plotDataAndPredictions)(\"#trained .plot\", trainingData.xs, trainingData.ys, predictionsDuring);\n\n          case 9:\n\n            // The function it takes must return a numerical estimate (i.e. loss)\n            // of how well we are doing using the current state of\n            // the variables we created at the start.\n\n            // This optimizer does the 'backward' step of our training process\n            // updating variables defined previously in order to minimize the\n            // loss.\n            optimizer.minimize(function () {\n              // Feed the examples into the model\n              var pred = predict(trainingData.xs);\n              return loss(pred, trainingData.ys);\n            });\n\n            // Use tf.nextFrame to not block the browser.\n            _context.next = 12;\n            return tf.nextFrame();\n\n          case 12:\n            iter++;\n            _context.next = 3;\n            break;\n\n          case 15:\n\n            // See what the final results predictions are after training.\n            (0, _ui.renderCoefficients)(\"#trained .coeff\", {\n              a: a.dataSync()[0],\n              b: b.dataSync()[0],\n              c: c.dataSync()[0],\n              d: d.dataSync()[0]\n            });\n            predictionsAfter = predict(trainingData.xs);\n            _context.next = 19;\n            return (0, _ui.plotDataAndPredictions)(\"#trained .plot\", trainingData.xs, trainingData.ys, predictionsAfter);\n\n          case 19:\n\n            predictionsAfter.dispose();\n\n          case 20:\n          case \"end\":\n            return _context.stop();\n        }\n      }\n    }, _callee, this);\n  }));\n\n  return function learnCoefficients() {\n    return _ref.apply(this, arguments);\n  };\n}(); /**\n      * @license\n      * Copyright 2018 Google LLC. All Rights Reserved.\n      * Licensed under the Apache License, Version 2.0 (the \"License\");\n      * you may not use this file except in compliance with the License.\n      * You may obtain a copy of the License at\n      *\n      * http://www.apache.org/licenses/LICENSE-2.0\n      *\n      * Unless required by applicable law or agreed to in writing, software\n      * distributed under the License is distributed on an \"AS IS\" BASIS,\n      * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n      * See the License for the specific language governing permissions and\n      * limitations under the License.\n      * =============================================================================\n      */\n\nvar _tfjs = require(\"@tensorflow/tfjs\");\n\nvar tf = _interopRequireWildcard(_tfjs);\n\nvar _data = require(\"./data\");\n\nvar _ui = require(\"./ui\");\n\nfunction _interopRequireWildcard(obj) { if (obj && obj.__esModule) { return obj; } else { var newObj = {}; if (obj != null) { for (var key in obj) { if (Object.prototype.hasOwnProperty.call(obj, key)) newObj[key] = obj[key]; } } newObj.default = obj; return newObj; } }\n\nfunction _interopRequireDefault(obj) { return obj && obj.__esModule ? obj : { default: obj }; }\n\n/**\n * We want to learn the coefficients that give correct solutions to the\n * following quadratic equation:\n *      y = a * x^3 + b * x^2 + c * x + d\n * In other words we want to learn values for:\n *      a\n *      b\n *      c\n *      d\n * Such that this function produces 'desired outputs' for y when provided\n * with x. We will provide some examples of 'xs' and 'ys' to allow this model\n * to learn what we mean by desired outputs and then use it to produce new\n * values of y that fit the curve implied by our example.\n */\n\n// Step 1. Set up variables, these are the things we want the model\n// to learn in order to do prediction accurately. We will initialize\n// them with random values.\nvar a = tf.variable(tf.scalar(Math.random()));\nvar b = tf.variable(tf.scalar(Math.random()));\nvar c = tf.variable(tf.scalar(Math.random()));\nvar d = tf.variable(tf.scalar(Math.random()));\n\n// Step 2. Create an optimizer, we will use this later. You can play\n// with some of these values to see how the model perfoms.\nvar numIterations = 350;\nvar learningRate = 0.1;\nvar optimizer = tf.train.sgd(learningRate);\n\n// Step 3. Write our training process functions.\n\n/*\n * This function represents our 'model'. Given an input 'x' it will try and\n * predict the appropriate output 'y'.\n *\n * It is also sometimes referred to as the 'forward' step of our training\n * process. Though we will use the same function for predictions later.\n *\n * @return number predicted y value\n */\nfunction predict(x) {\n  // y = a * x ^ 3 + b * x ^ 2 + c * x + d\n  return tf.tidy(function () {\n    return a.mul(x.pow(tf.scalar(3, \"int32\"))).add(b.mul(x.square())).add(c.mul(x)).add(d);\n  });\n}\n\n/*\n * This will tell us how good the 'prediction' is given what we actually\n * expected.\n *\n * prediction is a tensor with our predicted y values.\n * labels is a tensor with the y values the model should have predicted.\n */\nfunction loss(prediction, labels) {\n  // Having a good error function is key for training a machine learning model\n  var error = prediction.sub(labels).square().mean();\n  return error;\n}\n\nvar randomNumber = function randomNumber() {\n  return Math.random() * 2 - 1;\n};\n\nlearnCoefficients();"},"hash":"d255ef2b1e6e1946302cb6f56c4d6aa9","cacheData":{"env":{}}}